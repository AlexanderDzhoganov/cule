[Defaults]
adam_eps=0.00015
ale_start_steps=4000
atoms=51
batch_size=32
categorical=False
discount=0.99
double_q=False
dueling=False
evaluate=False
evaluation_episodes=10
evaluation_interval=200000
evaluation_size=500
gpu=0
hidden_size=512
history_length=4
learn_start=80000
log_interval=100
lr=0.0000625
max_episode_length=18000
max_grad_norm=1
memory_capacity=500000
multi_step=3
noisy_linear=False
noisy_std=0.1
normalize=False
num_ales=32
plot=True
priority_exponent=0.7
priority_replay=False
priority_weight=0.5
rainbow=False
replay_frequency=4
reward_clip=True
t_max=12500000
target_update=32000
v_max=10
v_min=-10
verbose=False
use_openai=False
